{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d82760",
   "metadata": {},
   "source": [
    "# **Book Recommendation System — Content Based Filtering Approach**\n",
    "\n",
    "**Author:** Milos Saric [https://saricmilos.com/]  \n",
    "**Date:** November 04, 2025 - November 18th, 2025  \n",
    "**Dataset:** Kaggle — *Book Recommendation Dataset*  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8d4cb",
   "metadata": {},
   "source": [
    "### Required Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.dataloader import load_all_csvs_from_folder\n",
    "from src.preprocess_user_books_ratings import preprocess_books_ratings_users\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e204e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = Path(r\"C:\\Users\\Milos\\Desktop\\ESCAPE_9-5\\PYTHON\\GitHub_Kaggle_Projects\\what-else-should-I-read\\datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d83857",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_all_csvs_from_folder(dataset_folder,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = preprocess_books_ratings_users(\n",
    "    datasets[\"Books\"],\n",
    "    datasets[\"Ratings\"],\n",
    "    datasets[\"Users\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be3dd4",
   "metadata": {},
   "source": [
    "# **1. Content Based Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f72eb",
   "metadata": {},
   "source": [
    "For **content-based recommendation**, one-hot encoding works well for columns with **low cardinality**.  \n",
    "\n",
    "However, for high-cardinality columns like `isbn` (149,833 unique values) or `book_title` (135,564 unique values), traditional one-hot encoding is **impractical**:\n",
    "\n",
    "- It creates **very large, sparse matrices**  \n",
    "- Consumes **excessive memory**  \n",
    "- Slows down computations  \n",
    "\n",
    "Alternative encoding methods (embeddings, hashing, or TF-IDF for text) are better suited for these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf8075",
   "metadata": {},
   "source": [
    "For content-based filtering, we focus on attributes that describe the item, not the use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_identifiers = merged_df[['isbn', 'book_title']].drop_duplicates(subset='book_title').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414117ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_features = merged_df[['book_title', 'book_author', 'year_of_publication', 'publisher', 'book_avg_rating']].copy()\n",
    "book_features['is_high_rating'] = (book_features['book_avg_rating'] >= 8).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287f3e3",
   "metadata": {},
   "source": [
    "Frequency encoding: encode each author/publisher by the number of books they have in the dataset or their average book rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding\n",
    "author_freq = book_features['book_author'].value_counts().to_dict()\n",
    "publisher_freq = book_features['publisher'].value_counts().to_dict()\n",
    "book_features['author_freq'] = book_features['book_author'].map(author_freq)\n",
    "book_features['publisher_freq'] = book_features['publisher'].map(publisher_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on book_title\n",
    "book_features = book_features.drop_duplicates(subset='book_title').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric columns\n",
    "cols_to_scale = ['author_freq', 'publisher_freq', 'year_of_publication', 'book_avg_rating']\n",
    "scaler = MinMaxScaler()\n",
    "book_features[cols_to_scale] = scaler.fit_transform(book_features[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2922f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_features[cols_to_scale].describe().T[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfde4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final book vectors\n",
    "book_vectors = book_features[['author_freq', 'publisher_freq', 'year_of_publication', 'book_avg_rating', 'is_high_rating']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f796b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_identifiers now aligns with book_vectors\n",
    "book_identifiers = book_identifiers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e87e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from book_title to vector index\n",
    "title_to_index = {title: idx for idx, title in enumerate(book_identifiers['book_title'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e552895",
   "metadata": {},
   "source": [
    "Build user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed21da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles = {}\n",
    "\n",
    "for user_id, group in merged_df.groupby('user_id'):\n",
    "    # map books to indices safely\n",
    "    book_indices = [title_to_index[title] for title in group['book_title'] if title in title_to_index]\n",
    "    \n",
    "    if not book_indices:  # skip users with no valid books\n",
    "        continue\n",
    "    \n",
    "    # average their vectors\n",
    "    user_vector = book_vectors[book_indices].mean(axis=0)\n",
    "    user_profiles[user_id] = user_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b995ecc",
   "metadata": {},
   "source": [
    "For a content based recommender using user profiles, we don’t need to precompute cosine similarity for all books. We compute a user vector by averaging the book vectors the user liked. To get recommendations, we compute cosine similarity between this single user vector and all book vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e366edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_id, top_n=5):\n",
    "    if user_id not in user_profiles:\n",
    "        return []\n",
    "    \n",
    "    user_vector = user_profiles[user_id].reshape(1, -1)\n",
    "    sims = cosine_similarity(user_vector, book_vectors).flatten()\n",
    "    \n",
    "    # exclude books the user has already rated\n",
    "    user_books = merged_df[merged_df['user_id'] == user_id]['book_title'].tolist()\n",
    "    \n",
    "    recommended_indices = [\n",
    "        i for i in sims.argsort()[::-1] if book_identifiers.iloc[i]['book_title'] not in user_books\n",
    "    ][:top_n]\n",
    "    \n",
    "    return book_identifiers.iloc[recommended_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: recommend top 5 books for user with ID 243\n",
    "recommended_books = recommend_books(user_id=243, top_n=5)\n",
    "\n",
    "# Show the titles and ISBNs\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e476aa3",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8b728",
   "metadata": {},
   "source": [
    "Item Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870eb74c",
   "metadata": {},
   "source": [
    "We compute similarity between books. When a user inputs a book title, you return the top-k most similar books based on their feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11847d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_to_index = {title: idx for idx, title in enumerate(book_identifiers['book_title'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build nearest neighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='brute')\n",
    "nn_model.fit(book_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b111ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_books(book_title, top_n=5):\n",
    "    if book_title not in title_to_index:\n",
    "        return []\n",
    "    \n",
    "    idx = title_to_index[book_title]\n",
    "    vector = book_vectors[idx].reshape(1, -1)\n",
    "    \n",
    "    distances, indices = nn_model.kneighbors(vector, n_neighbors=top_n+1)\n",
    "    indices = indices.flatten()\n",
    "    distances = distances.flatten()\n",
    "    \n",
    "    # exclude the book itself\n",
    "    indices = [i for i in indices if i != idx][:top_n]\n",
    "    \n",
    "    return book_identifiers.iloc[indices][['book_title', 'isbn']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_similar_books(\"1984\", top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_books (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
